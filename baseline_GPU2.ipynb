{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c1659e7-3da9-40d2-859b-bb74ec071dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 14 12:48:50 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Quadro RTX 6000                 On | 00000000:1B:00.0 Off |                  Off |\n",
      "| 33%   26C    P8               10W / 260W|  23893MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 6000                 On | 00000000:1C:00.0 Off |                  Off |\n",
      "| 33%   24C    P8                8W / 260W|   2339MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 6000                 On | 00000000:1D:00.0 Off |                  Off |\n",
      "| 33%   27C    P8               15W / 260W|   2339MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 6000                 On | 00000000:1E:00.0 Off |                  Off |\n",
      "| 33%   26C    P8                7W / 260W|   2339MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  Quadro RTX 6000                 On | 00000000:3D:00.0 Off |                  Off |\n",
      "| 33%   23C    P8               13W / 260W|   2339MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  Quadro RTX 6000                 On | 00000000:3F:00.0 Off |                  Off |\n",
      "| 33%   25C    P8                4W / 260W|   2339MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  Quadro RTX 6000                 On | 00000000:40:00.0 Off |                  Off |\n",
      "| 35%   26C    P8               17W / 260W|   2339MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  Quadro RTX 6000                 On | 00000000:41:00.0 Off |                  Off |\n",
      "| 34%   25C    P8               16W / 260W|   2339MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   3380490      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    0   N/A  N/A   3398004      C   /opt/anaconda3/bin/python                   274MiB |\n",
      "|    0   N/A  N/A   3400215      C   /opt/anaconda3/bin/python                   162MiB |\n",
      "|    0   N/A  N/A   3441102      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    0   N/A  N/A   3467292      C   /opt/anaconda3/bin/python                  2494MiB |\n",
      "|    0   N/A  N/A   3490744      C   /opt/anaconda3/bin/python                  3426MiB |\n",
      "|    0   N/A  N/A   3500473      C   /opt/anaconda3/bin/python                 15986MiB |\n",
      "|    0   N/A  N/A   3500824      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    0   N/A  N/A   3549132      C   /opt/anaconda3/bin/python                   614MiB |\n",
      "|    1   N/A  N/A   3380490      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    1   N/A  N/A   3400216      C   /opt/anaconda3/bin/python                   162MiB |\n",
      "|    1   N/A  N/A   3441102      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    1   N/A  N/A   3467292      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    1   N/A  N/A   3490744      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    1   N/A  N/A   3500473      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    1   N/A  N/A   3500824      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    1   N/A  N/A   3549132      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    2   N/A  N/A   3380490      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    2   N/A  N/A   3400224      C   /opt/anaconda3/bin/python                   162MiB |\n",
      "|    2   N/A  N/A   3441102      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    2   N/A  N/A   3467292      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    2   N/A  N/A   3490744      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    2   N/A  N/A   3500473      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    2   N/A  N/A   3500824      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    2   N/A  N/A   3549132      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    3   N/A  N/A   3380490      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    3   N/A  N/A   3400221      C   /opt/anaconda3/bin/python                   162MiB |\n",
      "|    3   N/A  N/A   3441102      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    3   N/A  N/A   3467292      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    3   N/A  N/A   3490744      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    3   N/A  N/A   3500473      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    3   N/A  N/A   3500824      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    3   N/A  N/A   3549132      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    4   N/A  N/A   3380490      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    4   N/A  N/A   3400229      C   /opt/anaconda3/bin/python                   162MiB |\n",
      "|    4   N/A  N/A   3441102      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    4   N/A  N/A   3467292      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    4   N/A  N/A   3490744      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    4   N/A  N/A   3500473      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    4   N/A  N/A   3500824      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    4   N/A  N/A   3549132      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    5   N/A  N/A   3380490      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    5   N/A  N/A   3400227      C   /opt/anaconda3/bin/python                   162MiB |\n",
      "|    5   N/A  N/A   3441102      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    5   N/A  N/A   3467292      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    5   N/A  N/A   3490744      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    5   N/A  N/A   3500473      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    5   N/A  N/A   3500824      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    5   N/A  N/A   3549132      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    6   N/A  N/A   3380490      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    6   N/A  N/A   3400232      C   /opt/anaconda3/bin/python                   162MiB |\n",
      "|    6   N/A  N/A   3441102      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    6   N/A  N/A   3467292      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    6   N/A  N/A   3490744      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    6   N/A  N/A   3500473      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    6   N/A  N/A   3500824      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    6   N/A  N/A   3549132      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    7   N/A  N/A   3380490      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    7   N/A  N/A   3400235      C   /opt/anaconda3/bin/python                   162MiB |\n",
      "|    7   N/A  N/A   3441102      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    7   N/A  N/A   3467292      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    7   N/A  N/A   3490744      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    7   N/A  N/A   3500473      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    7   N/A  N/A   3500824      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "|    7   N/A  N/A   3549132      C   /opt/anaconda3/bin/python                   310MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b7ff29-4ef0-479c-bf69-49700c0716c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 12:48:52.037454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "from Loader import train_data, test_data\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "783ade79-6690-4cd3-a167-72e046765e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 12:48:53.470810: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-14 12:48:53.477756: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-05-14 12:48:53.478803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-05-14 12:48:55.221418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:1b:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:55.221966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:1c:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:55.222414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:1d:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:55.222852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:1e:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:55.223280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: \n",
      "pciBusID: 0000:3d:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:55.223697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties: \n",
      "pciBusID: 0000:3f:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:55.224112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties: \n",
      "pciBusID: 0000:40:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:55.224531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties: \n",
      "pciBusID: 0000:41:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:55.224573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-05-14 12:48:55.226466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-05-14 12:48:55.226539: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-05-14 12:48:55.228232: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-05-14 12:48:55.228577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-05-14 12:48:55.230472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-05-14 12:48:55.231523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-05-14 12:48:55.235463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-05-14 12:48:55.242028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\n",
      "2023-05-14 12:48:55.242083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-05-14 12:48:59.123294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-05-14 12:48:59.123332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 4 5 6 7 \n",
      "2023-05-14 12:48:59.123339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y Y Y Y Y Y \n",
      "2023-05-14 12:48:59.123343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y Y Y Y Y Y \n",
      "2023-05-14 12:48:59.123347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N Y Y Y Y Y \n",
      "2023-05-14 12:48:59.123351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   Y Y Y N Y Y Y Y \n",
      "2023-05-14 12:48:59.123354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 4:   Y Y Y Y N Y Y Y \n",
      "2023-05-14 12:48:59.123374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 5:   Y Y Y Y Y N Y Y \n",
      "2023-05-14 12:48:59.123378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 6:   Y Y Y Y Y Y N Y \n",
      "2023-05-14 12:48:59.123382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 7:   Y Y Y Y Y Y Y N \n",
      "2023-05-14 12:48:59.128610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12106 MB memory) -> physical GPU (device: 0, name: Quadro RTX 6000, pci bus id: 0000:1b:00.0, compute capability: 7.5)\n",
      "2023-05-14 12:48:59.131184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12106 MB memory) -> physical GPU (device: 1, name: Quadro RTX 6000, pci bus id: 0000:1c:00.0, compute capability: 7.5)\n",
      "2023-05-14 12:48:59.132743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12106 MB memory) -> physical GPU (device: 2, name: Quadro RTX 6000, pci bus id: 0000:1d:00.0, compute capability: 7.5)\n",
      "2023-05-14 12:48:59.134794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12106 MB memory) -> physical GPU (device: 3, name: Quadro RTX 6000, pci bus id: 0000:1e:00.0, compute capability: 7.5)\n",
      "2023-05-14 12:48:59.136265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 12106 MB memory) -> physical GPU (device: 4, name: Quadro RTX 6000, pci bus id: 0000:3d:00.0, compute capability: 7.5)\n",
      "2023-05-14 12:48:59.138271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 12106 MB memory) -> physical GPU (device: 5, name: Quadro RTX 6000, pci bus id: 0000:3f:00.0, compute capability: 7.5)\n",
      "2023-05-14 12:48:59.140901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 12106 MB memory) -> physical GPU (device: 6, name: Quadro RTX 6000, pci bus id: 0000:40:00.0, compute capability: 7.5)\n",
      "2023-05-14 12:48:59.142683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 12106 MB memory) -> physical GPU (device: 7, name: Quadro RTX 6000, pci bus id: 0000:41:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.operation_timeout_in_ms=60000\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0449d7e6-7a0b-41a6-b93d-dc4908b17073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 12:48:59.158269: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-05-14 12:48:59.158917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:1b:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:59.159357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:1c:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:59.159770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:1d:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:59.160185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:1e:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:59.160592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: \n",
      "pciBusID: 0000:3d:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:59.160995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties: \n",
      "pciBusID: 0000:3f:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:59.161396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties: \n",
      "pciBusID: 0000:40:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:59.161833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties: \n",
      "pciBusID: 0000:41:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:48:59.161881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-05-14 12:48:59.161906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-05-14 12:48:59.161919: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-05-14 12:48:59.161932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-05-14 12:48:59.161944: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-05-14 12:48:59.161956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-05-14 12:48:59.161968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-05-14 12:48:59.161980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-05-14 12:48:59.168299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "# Following code releases unused GPU memory for others to use.\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c5f3963-971c-44aa-8405-3867cd97381b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 3073)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3063</th>\n",
       "      <th>3064</th>\n",
       "      <th>3065</th>\n",
       "      <th>3066</th>\n",
       "      <th>3067</th>\n",
       "      <th>3068</th>\n",
       "      <th>3069</th>\n",
       "      <th>3070</th>\n",
       "      <th>3071</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>112</td>\n",
       "      <td>113</td>\n",
       "      <td>119</td>\n",
       "      <td>117</td>\n",
       "      <td>118</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>115</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>91</td>\n",
       "      <td>86</td>\n",
       "      <td>99</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>98</td>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>205</td>\n",
       "      <td>215</td>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>223</td>\n",
       "      <td>228</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>121</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>185</td>\n",
       "      <td>208</td>\n",
       "      <td>130</td>\n",
       "      <td>162</td>\n",
       "      <td>185</td>\n",
       "      <td>153</td>\n",
       "      <td>185</td>\n",
       "      <td>208</td>\n",
       "      <td>162</td>\n",
       "      <td>...</td>\n",
       "      <td>167</td>\n",
       "      <td>178</td>\n",
       "      <td>172</td>\n",
       "      <td>166</td>\n",
       "      <td>177</td>\n",
       "      <td>171</td>\n",
       "      <td>165</td>\n",
       "      <td>176</td>\n",
       "      <td>170</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3073 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ... 3063 3064 3065 3066  \\\n",
       "0  114  112  113  119  117  118  117  117  115  111  ...  100   91   86   99   \n",
       "1  206  204  205  215  213  214  224  222  223  228  ...  126  125  123  124   \n",
       "2  153  185  208  130  162  185  153  185  208  162  ...  167  178  172  166   \n",
       "\n",
       "  3067 3068 3069 3070 3071 label  \n",
       "0   91   88   98   90   87  Fake  \n",
       "1  123  121  123  122  120  Fake  \n",
       "2  177  171  165  176  170  Fake  \n",
       "\n",
       "[3 rows x 3073 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = train_data()\n",
    "print(df_train.shape)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e88461-1315-470a-9288-69901d76a6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3073)\n"
     ]
    }
   ],
   "source": [
    "df_sample = df_train.sample(frac=0.1, random_state=0)\n",
    "print(df_sample.shape)\n",
    "X = df_sample.drop('label', axis=1)\n",
    "X = (X-X.mean())/X.std()\n",
    "y = df_sample.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0f75ebe-aaec-4699-af0f-f404282391a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001   0.000325 0.00055  0.000775 0.001   ]\n"
     ]
    }
   ],
   "source": [
    "# reg_stren = [0.0005, 0.001, 0.005]\n",
    "reg_stren = np.linspace(0.0001, 0.001, 5)\n",
    "print(reg_stren)\n",
    "pen = ['l2', 'l1']\n",
    "solv = ['saga']\n",
    "iter = [5000, 10000]\n",
    "grid = {'C':reg_stren, 'penalty':pen, 'solver':solv, 'max_iter':iter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21fcb27-bd10-4a5e-899f-2eecf6c1acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 12:49:32.002693: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-05-14 12:49:32.003523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:1b:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:49:32.004086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:1c:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:49:32.004601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:1d:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:49:32.005112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:1e:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:49:32.005639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: \n",
      "pciBusID: 0000:3d:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:49:32.006159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties: \n",
      "pciBusID: 0000:3f:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:49:32.006665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties: \n",
      "pciBusID: 0000:40:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:49:32.007169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties: \n",
      "pciBusID: 0000:41:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.64GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-14 12:49:32.007215: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-05-14 12:49:32.007244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-05-14 12:49:32.007260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-05-14 12:49:32.007276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-05-14 12:49:32.007291: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-05-14 12:49:32.007306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-05-14 12:49:32.007322: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-05-14 12:49:32.007338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-05-14 12:49:32.015076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\n",
      "2023-05-14 12:49:32.015219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-05-14 12:49:32.015227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 4 5 6 7 \n",
      "2023-05-14 12:49:32.015234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y Y Y Y Y Y \n",
      "2023-05-14 12:49:32.015239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y Y Y Y Y Y \n",
      "2023-05-14 12:49:32.015244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N Y Y Y Y Y \n",
      "2023-05-14 12:49:32.015251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   Y Y Y N Y Y Y Y \n",
      "2023-05-14 12:49:32.015256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 4:   Y Y Y Y N Y Y Y \n",
      "2023-05-14 12:49:32.015261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 5:   Y Y Y Y Y N Y Y \n",
      "2023-05-14 12:49:32.015266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 6:   Y Y Y Y Y Y N Y \n",
      "2023-05-14 12:49:32.015271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 7:   Y Y Y Y Y Y Y N \n",
      "2023-05-14 12:49:32.019955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12106 MB memory) -> physical GPU (device: 0, name: Quadro RTX 6000, pci bus id: 0000:1b:00.0, compute capability: 7.5)\n",
      "2023-05-14 12:49:32.020495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12106 MB memory) -> physical GPU (device: 1, name: Quadro RTX 6000, pci bus id: 0000:1c:00.0, compute capability: 7.5)\n",
      "2023-05-14 12:49:32.021021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12106 MB memory) -> physical GPU (device: 2, name: Quadro RTX 6000, pci bus id: 0000:1d:00.0, compute capability: 7.5)\n",
      "2023-05-14 12:49:32.021541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12106 MB memory) -> physical GPU (device: 3, name: Quadro RTX 6000, pci bus id: 0000:1e:00.0, compute capability: 7.5)\n",
      "2023-05-14 12:49:32.022073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 12106 MB memory) -> physical GPU (device: 4, name: Quadro RTX 6000, pci bus id: 0000:3d:00.0, compute capability: 7.5)\n",
      "2023-05-14 12:49:32.022610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 12106 MB memory) -> physical GPU (device: 5, name: Quadro RTX 6000, pci bus id: 0000:3f:00.0, compute capability: 7.5)\n",
      "2023-05-14 12:49:32.023154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 12106 MB memory) -> physical GPU (device: 6, name: Quadro RTX 6000, pci bus id: 0000:40:00.0, compute capability: 7.5)\n",
      "2023-05-14 12:49:32.023690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 12106 MB memory) -> physical GPU (device: 7, name: Quadro RTX 6000, pci bus id: 0000:41:00.0, compute capability: 7.5)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "with strategy.scope():\n",
    "\n",
    "    \n",
    "    ####################################################################\n",
    "    # Baseline Logistic Regression\n",
    "    time_start = time()\n",
    "    lgr = LogisticRegression(n_jobs = -1)\n",
    "    lgrCV = GridSearchCV(lgr, param_grid=grid, return_train_score=True, n_jobs=-1)\n",
    "    # lgr.fit(X,y)\n",
    "    lgrCV.fit(X,y)\n",
    "\n",
    "    time_stop = time()\n",
    "    print('Comp Time:', (time_stop-time_start)/60, 'min')\n",
    "    \n",
    "#     ####################################################################\n",
    "#     # Cross Validation\n",
    "    \n",
    "#     ## L2 Regularization\n",
    "#     ts = time()\n",
    "#     lgrcv2 = LogisticRegressionCV(cv=3, \n",
    "#                                   random_state=0, \n",
    "#                                   n_jobs=-1,\n",
    "#                                   penalty='l2',\n",
    "#                                   solver='sag',\n",
    "#                                   max_iter = 5000)\n",
    "\n",
    "#     lgrcv2.fit(X,y)\n",
    "#     tss= time()\n",
    "#     print('CV l2 Time:', (tss-ts)/60, 'min')\n",
    "#     print()\n",
    "#     print('CV l2 Baseline:', lgrcv2.score(X,y))\n",
    "#     print()\n",
    "    \n",
    "    \n",
    "#     ####################################################################\n",
    "    \n",
    "#     ## L1 Regularization \n",
    "#     ts = time()\n",
    "#     lgrcv1 = LogisticRegressionCV(cv=3, \n",
    "#                                   random_state=0, \n",
    "#                                   n_jobs=-1,\n",
    "#                                   penalty='l1',\n",
    "#                                   solver='saga',\n",
    "#                                   max_iter = 10000)\n",
    "\n",
    "#     lgrcv1.fit(X,y)\n",
    "#     tss= time()\n",
    "#     print('CV l1 Time:', (tss-ts)/60, 'min')\n",
    "#     print()\n",
    "#     print('CV l1 Baseline:', lgrcv1.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728dce35-e4a2-42d6-ab01-01130bb10841",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hyper Parameters:', lgrCV.best_params_)\n",
    "print('R2', lgrCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce132cc0-e339-4ace-9f11-2b308594e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(C=lgrCV.best_params_['C'],\n",
    "                         penalty=lgrCV.best_params_['penalty'],\n",
    "                         solver=lgrCV.best_params_['solver'],\n",
    "                         max_iter=lgrCV.best_params_['max_iter'])\n",
    "lgr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f4469-27cc-41b9-8c78-32b20dd1e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = lgrCV.cv_results_['mean_test_score'].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54813e34-15bc-45a2-a1ee-79a99aaf03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = lgrCV.cv_results_['mean_train_score'][ix].round(4)\n",
    "accuracy_valid = lgrCV.cv_results_['mean_test_score'].max().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ec65e-1b01-4865-857b-3f107eaed2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Accuracy:', accuracy_train)\n",
    "print()\n",
    "print('Validation Accuracy:', accuracy_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14442bad-b255-4e2b-8379-d662e7dc1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = test_data()\n",
    "print(df_test.shape)\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9a4142-faf7-4c3a-81b1-5f7def5de7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestL2_C = lgrcv2.C_\n",
    "# bestL1_C = lgrcv1.C_\n",
    "\n",
    "# print('Best L2 param:', bestL2_C)\n",
    "# print()\n",
    "# print('Best L1 param:', bestL1_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33131f1c-ea23-4236-ba2a-ee2e45142ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts = time()\n",
    "# lgrcv2 = LogisticRegressionCV(cv=5,\n",
    "#                               Cs=[bestL2_C],\n",
    "#                               random_state=0, \n",
    "#                               n_jobs=-1,\n",
    "#                               penalty='l2',\n",
    "#                               solver='sag',\n",
    "#                               max_iter = 5000)\n",
    "\n",
    "# lgrcv2.fit(X,y)\n",
    "# tss = time()\n",
    "# print('CV l2 Time:', tss-ts)\n",
    "# print()\n",
    "# print('CV l2 Baseline:', lgrcv2.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457f35ae-f2c0-417b-957c-3e768d1449f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(True)\n",
    "# gpus = tf.config.list_logical_devices('GPU')\n",
    "# strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "# with strategy.scope():\n",
    "#     ts = time()\n",
    "#     lgrcv1 = LogisticRegressionCV(cv=5,\n",
    "#                                   Cs=[bestL1_C],\n",
    "#                                   random_state=0, \n",
    "#                                   n_jobs=-1,\n",
    "#                                   penalty='l1',\n",
    "#                                   solver='saga',\n",
    "#                                   max_iter = 10000)\n",
    "\n",
    "#     lgrcv1.fit(X,y)\n",
    "#     tss = time()\n",
    "#     print('CV l1 Time:', tss-ts)\n",
    "#     print()\n",
    "#     print('CV l1 Baseline:', lgrcv1.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6715c1d3-6872-418c-912f-cbf0b5facd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultsl2 = lgrcv2.coef_\n",
    "# resultsl2 = resultsl2.reshape([32,32,3])\n",
    "# x = []\n",
    "# y = []\n",
    "\n",
    "# xred = []\n",
    "# yred = []\n",
    "\n",
    "# xgreen = []\n",
    "# ygreen = []\n",
    "\n",
    "# xblue = []\n",
    "# yblue = []\n",
    "\n",
    "# weight = [0.001, 0.005, 0.01]\n",
    "\n",
    "# cmap = plt.cm.get_cmap('jet')\n",
    "\n",
    "# for w in range(len(weight)):\n",
    "#     for rgb in range(3):\n",
    "#         mask = np.abs(resultsl2[:, :, rgb]) > weight[w]\n",
    "#         heat_map = np.zeros((32, 32))\n",
    "#         heat_map[mask] = np.abs(resultsl2[mask][:, rgb])\n",
    "\n",
    "#         plt.imshow(heat_map, cmap=cmap, alpha=0.5)  # Display the heat map\n",
    "#         plt.colorbar()\n",
    "\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e23d0a-b2ec-455f-b65b-cec35769a49d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
